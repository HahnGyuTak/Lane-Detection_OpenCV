{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9de0b9",
   "metadata": {},
   "source": [
    "# 소실점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec9b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def grayscale(img): # 흑백이미지로 변환\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold): # Canny알고리즘\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kerner_size): # 가우시안 필터\n",
    "    return cv2.GaussianBlur(img, (kerner_size, kerner_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices, color3 = (255, 255, 255), color1 = 255):\n",
    "    #ROI setting\n",
    "    mask = np.zeros_like(img) # img와 같은 크기의 빈 이미지\n",
    "\n",
    "    if len(img.shape) > 2 : #if color image (3 channels)\n",
    "        color = color3\n",
    "    else : #if black&white image ( 1 channel)\n",
    "        color = color1\n",
    "    \n",
    "    #vertices에 정한 점들로 이루어진 다각형 부분(ROI부분)을 color로 채움\n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "    \n",
    "    #이미지와 color로 체워진 ROI를 합침\n",
    "    ROI_img = cv2.bitwise_and(img, mask)\n",
    "    return ROI_img\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap): #허프 변환\n",
    "    lines = cv2.HoughLines(img, rho, theta, threshold, np.array([]))#, minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype = np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    \n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, a = 1, b = 1., c = 0.): #두 이지미 합치기\n",
    "    return cv2.addWeighted(initial_img, a, img, b, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c32d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitline(img, f_lines):\n",
    "    lines = np.squeeze(f_lines)\n",
    "    lines = lines.reshape(lines.shape[0] * 2, 2)\n",
    "    rows, cols = img.shape[:2]\n",
    "    output = cv2.fitLine(lines, cv2.DIST_L2, 0, 0.01, 0.01)\n",
    "    \n",
    "    vx, vy, x, y = output[0], output[1], output[2], output[3]\n",
    "    x1, y1 = int(((img.shape[0] - 1) - y) / vy * vx + x), img.shape[0] - 1\n",
    "    x2, y2 = int(((img.shape[0]/2 + 100) - y) / vy * vx + x), int(img.shape[0] / 2 + 100)\n",
    "    \n",
    "    result = [x1,y1, x2, y2]\n",
    "    return result\n",
    "def draw_lines(img, lines, color=[0,0,255], thickness = 2): #선그리기\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "#def draw_lines(img, lines, color=[0,0,255], thickness = 10): #선그리기\n",
    "#   cv2.line(img, (lines[0], lines[1]), (lines[2], lines[3]), color, thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628d59d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7867b7f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m roi_img \u001b[38;5;241m=\u001b[39m region_of_interest(canny_img, vertices) \u001b[38;5;66;03m# vertices에 정한 점들을 기준으로 ROI이미지 생성\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#cv2.imshow('roi', roi_img)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m line_arr \u001b[38;5;241m=\u001b[39m \u001b[43mhough_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroi_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m180\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#허프 변환\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#line_arr = np.squeeze(line_arr)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres\u001b[39m\u001b[38;5;124m'\u001b[39m, weighted_img(line_arr, image))\n",
      "Cell \u001b[0;32mIn [3], line 32\u001b[0m, in \u001b[0;36mhough_lines\u001b[0;34m(img, rho, theta, threshold, min_line_len, max_line_gap)\u001b[0m\n\u001b[1;32m     30\u001b[0m lines \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mHoughLines(img, rho, theta, threshold, np\u001b[38;5;241m.\u001b[39marray([]))\u001b[38;5;66;03m#, minLineLength=min_line_len, maxLineGap=max_line_gap)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m line_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m3\u001b[39m), dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mdraw_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m line_img\n",
      "Cell \u001b[0;32mIn [2], line 15\u001b[0m, in \u001b[0;36mdraw_lines\u001b[0;34m(img, lines, color, thickness)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_lines\u001b[39m(img, lines, color\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m], thickness \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m): \u001b[38;5;66;03m#선그리기\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m---> 15\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x1, y1, x2, y2 \u001b[38;5;129;01min\u001b[39;00m line:\n\u001b[1;32m     16\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mline(img, (x1, y1), (x2, y2), color, thickness)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "image = cv2.imread(\"slope_test.jpg\")\n",
    "    \n",
    "height, width = image.shape[:2]\n",
    "\n",
    "gray_img = grayscale(image) # 흑백이미지로 변환\n",
    "\n",
    "blur_img = gaussian_blur(gray_img, 3) # Blur 효과\n",
    "\n",
    "canny_img = canny(blur_img, 70, 210) # Canny Edge 알고리ㅑ\n",
    "\n",
    "#cv2.imshow('canny', canny_img) # Canny 이미지 출력\n",
    "\n",
    "vertices = np.array([[(50, height), (width/2 - 45, height/2 + 60), (width/2 + 45, height/2 + 60), (width-50, height)]], dtype=np.int32)\n",
    "\n",
    "roi_img = region_of_interest(canny_img, vertices) # vertices에 정한 점들을 기준으로 ROI이미지 생성\n",
    "#cv2.imshow('roi', roi_img)\n",
    "\n",
    "line_arr = hough_lines(roi_img, 1, 1 * np.pi/180, 30, 10 ,20) #허프 변환\n",
    "#line_arr = np.squeeze(line_arr)\n",
    "\n",
    "cv2.imshow('res', weighted_img(line_arr, image))\n",
    "\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9227444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 960, 3)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'line_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mline_arr\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'line_arr' is not defined"
     ]
    }
   ],
   "source": [
    "print(image.shape)\n",
    "print(line_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe593a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2641363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "663851dd",
   "metadata": {},
   "source": [
    "# 동영상 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c4d2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(\"solidWhiteRight.mp4\")\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, image = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    gray_img = grayscale(image) # 흑백이미지로 변환\n",
    "\n",
    "    blur_img = gaussian_blur(gray_img, 3) # Blur 효과\n",
    "\n",
    "    canny_img = canny(blur_img, 70, 210) # Canny Edge 알고리ㅑ\n",
    "\n",
    "    cv2.imshow('canny', canny_img) # Canny 이미지 출력\n",
    "\n",
    "    vertices = np.array([[(50, height), (width/2 - 45, height/2 + 60), (width/2 + 45, height/2 + 60), (width-50, height)]], dtype=np.int32)\n",
    "\n",
    "    roi_img = region_of_interest(canny_img, vertices) # vertices에 정한 점들을 기준으로 ROI이미지 생성\n",
    "    #cv2.imshow('roi', roi_img)\n",
    "\n",
    "    line_arr = hough_lines(roi_img, 1, 1 * np.pi/180, 30, 10 ,20) #허프 변환\n",
    "    line_arr = np.squeeze(line_arr)\n",
    "\n",
    "    #기울기 구하기\n",
    "    slope_degree = (np.arctan2(line_arr[:,1] - line_arr[:,3], line_arr[:,0] - line_arr[:, 2]) * 180) / np.pi\n",
    "\n",
    "    #수평 기울기 제한\n",
    "    line_arr = line_arr[np.abs(slope_degree) < 160]\n",
    "    slope_degree = slope_degree[np.abs(slope_degree) < 160]\n",
    "\n",
    "    #수직 기울기 제한\n",
    "    line_arr = line_arr[np.abs(slope_degree) > 95]\n",
    "    slope_degree = slope_degree[np.abs(slope_degree) > 95]\n",
    "\n",
    "    #필터링 직선 버리기\n",
    "    L_lines, R_lines = line_arr[(slope_degree > 0), :], line_arr[(slope_degree < 0), :]\n",
    "    temp = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "    L_lines, R_lines = L_lines[:,None], R_lines[:,None]\n",
    "\n",
    "    #왼쪽 오른쪽 각각 대표선 구하기\n",
    "    left_fit_line = get_fitline(image, L_lines)\n",
    "    right_fit_line = get_fitline(image, R_lines)\n",
    "\n",
    "    #대표선 그리기\n",
    "    draw_lines(temp, left_fit_line)\n",
    "    draw_lines(temp, right_fit_line)\n",
    "\n",
    "    result = weighted_img(temp, image)\n",
    "    cv2.imshow('result', result)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49486f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
